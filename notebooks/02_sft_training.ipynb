{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üéì SFT Training - Supervised Fine-Tuning\n",
                "\n",
                "Fine-tune Gemma to output `<reasoning>...<answer>` format.\n",
                "\n",
                "**Time estimate:** ~2-3 hours on Kaggle TPU"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import json\n",
                "import time\n",
                "import yaml\n",
                "from datetime import datetime\n",
                "\n",
                "import jax\n",
                "import jax.numpy as jnp\n",
                "from transformers import AutoTokenizer\n",
                "\n",
                "print(f\"JAX devices: {jax.device_count()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# SFT Configuration\n",
                "CFG = {\n",
                "    'model_name': 'google/gemma-3-1b-it',\n",
                "    'learning_rate': 1e-5,\n",
                "    'batch_size': 4,\n",
                "    'grad_accum': 8,\n",
                "    'num_epochs': 2,\n",
                "    'max_length': 1024,\n",
                "    'warmup_ratio': 0.03,\n",
                "    'save_minutes': 30,\n",
                "    'lora_r': 16,\n",
                "    'lora_alpha': 32,\n",
                "    'seed': 42\n",
                "}\n",
                "\n",
                "print(\"üìã Configuration:\")\n",
                "for k, v in CFG.items():\n",
                "    print(f\"  {k}: {v}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load Tokenizer & Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tokenizer = AutoTokenizer.from_pretrained(CFG['model_name'])\n",
                "print(f\"‚úÖ Tokenizer loaded: {CFG['model_name']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load model with Tunix\n",
                "# NOTE: Adjust imports based on actual Tunix API\n",
                "try:\n",
                "    from tunix import modeling\n",
                "    model = modeling.Gemma.from_pretrained(CFG['model_name'])\n",
                "    print(\"‚úÖ Model loaded via Tunix\")\n",
                "except ImportError:\n",
                "    print(\"‚ö†Ô∏è Tunix not available - using placeholder\")\n",
                "    model = None"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Load Training Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_jsonl(path):\n",
                "    data = []\n",
                "    with open(path, 'r', encoding='utf-8') as f:\n",
                "        for line in f:\n",
                "            data.append(json.loads(line.strip()))\n",
                "    return data\n",
                "\n",
                "train_data = load_jsonl('data/tokenized/train.jsonl')\n",
                "val_data = load_jsonl('data/tokenized/valid.jsonl')\n",
                "\n",
                "print(f\"‚úÖ Loaded {len(train_data)} train, {len(val_data)} val examples\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Create Data Batches"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "\n",
                "def create_batches(data, batch_size, shuffle=True):\n",
                "    \"\"\"Create batches from tokenized data.\"\"\"\n",
                "    if shuffle:\n",
                "        np.random.shuffle(data)\n",
                "    \n",
                "    batches = []\n",
                "    for i in range(0, len(data), batch_size):\n",
                "        batch = data[i:i+batch_size]\n",
                "        \n",
                "        # Pad to max length in batch\n",
                "        max_len = max(len(ex['input_ids']) for ex in batch)\n",
                "        \n",
                "        input_ids = []\n",
                "        attention_mask = []\n",
                "        \n",
                "        for ex in batch:\n",
                "            ids = ex['input_ids']\n",
                "            mask = ex['attention_mask']\n",
                "            pad_len = max_len - len(ids)\n",
                "            \n",
                "            input_ids.append(ids + [tokenizer.pad_token_id or 0] * pad_len)\n",
                "            attention_mask.append(mask + [0] * pad_len)\n",
                "        \n",
                "        batches.append({\n",
                "            'input_ids': jnp.array(input_ids),\n",
                "            'attention_mask': jnp.array(attention_mask)\n",
                "        })\n",
                "    \n",
                "    return batches\n",
                "\n",
                "# Test batch creation\n",
                "test_batches = create_batches(train_data[:16], CFG['batch_size'])\n",
                "print(f\"‚úÖ Created {len(test_batches)} test batches\")\n",
                "print(f\"   Batch shape: {test_batches[0]['input_ids'].shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Training Loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training state\n",
                "start_time = time.time()\n",
                "last_save_time = start_time\n",
                "global_step = 0\n",
                "train_losses = []\n",
                "\n",
                "os.makedirs('checkpoints/sft', exist_ok=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# SFT Training Loop (skeleton)\n",
                "# NOTE: Adapt to actual Tunix trainer API\n",
                "\n",
                "def train_epoch(epoch):\n",
                "    global global_step, last_save_time\n",
                "    \n",
                "    batches = create_batches(train_data, CFG['batch_size'])\n",
                "    epoch_losses = []\n",
                "    \n",
                "    for i, batch in enumerate(batches):\n",
                "        # === Training step ===\n",
                "        # loss = trainer.train_step(batch)\n",
                "        loss = 0.5  # Placeholder\n",
                "        \n",
                "        epoch_losses.append(loss)\n",
                "        global_step += 1\n",
                "        \n",
                "        # Log every 50 steps\n",
                "        if global_step % 50 == 0:\n",
                "            avg_loss = sum(epoch_losses[-50:]) / min(50, len(epoch_losses))\n",
                "            elapsed = (time.time() - start_time) / 60\n",
                "            print(f\"Step {global_step} | Loss: {avg_loss:.4f} | Time: {elapsed:.1f}m\")\n",
                "        \n",
                "        # Save checkpoint every N minutes\n",
                "        if (time.time() - last_save_time) > CFG['save_minutes'] * 60:\n",
                "            save_checkpoint(f\"sft_step_{global_step}\")\n",
                "            last_save_time = time.time()\n",
                "    \n",
                "    return sum(epoch_losses) / len(epoch_losses)\n",
                "\n",
                "def save_checkpoint(name):\n",
                "    path = f\"checkpoints/sft/{name}\"\n",
                "    os.makedirs(path, exist_ok=True)\n",
                "    \n",
                "    # Save metadata\n",
                "    meta = {\n",
                "        'step': global_step,\n",
                "        'time': datetime.now().isoformat(),\n",
                "        'config': CFG\n",
                "    }\n",
                "    with open(f\"{path}/metadata.json\", 'w') as f:\n",
                "        json.dump(meta, f, indent=2)\n",
                "    \n",
                "    # Save model\n",
                "    # model.save_pretrained(path)\n",
                "    \n",
                "    print(f\"üíæ Saved checkpoint: {path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run training\n",
                "print(\"üöÄ Starting SFT Training...\")\n",
                "print(f\"   Epochs: {CFG['num_epochs']}\")\n",
                "print(f\"   Batch size: {CFG['batch_size']} x {CFG['grad_accum']} = {CFG['batch_size'] * CFG['grad_accum']}\")\n",
                "print()\n",
                "\n",
                "for epoch in range(CFG['num_epochs']):\n",
                "    print(f\"=== Epoch {epoch+1}/{CFG['num_epochs']} ===\")\n",
                "    avg_loss = train_epoch(epoch)\n",
                "    print(f\"Epoch {epoch+1} avg loss: {avg_loss:.4f}\")\n",
                "    \n",
                "    # Save end of epoch\n",
                "    save_checkpoint(f\"sft_epoch_{epoch+1}\")\n",
                "\n",
                "print(\"\\n‚úÖ SFT Training complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Quick Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test generation\n",
                "test_prompt = \"\"\"Q: A store has 45 apples. If they sell 12 apples, how many are left?\n",
                "A:\n",
                "\"\"\"\n",
                "\n",
                "# Generate\n",
                "# output = model.generate(test_prompt, max_length=256)\n",
                "output = \"\"\"<reasoning>\n",
                "Step 1: Start with 45 apples\n",
                "Step 2: Subtract 12 sold apples\n",
                "Step 3: 45 - 12 = 33\n",
                "</reasoning>\n",
                "<answer>33 apples</answer>\"\"\"  # Placeholder\n",
                "\n",
                "print(\"üìù Test generation:\")\n",
                "print(test_prompt)\n",
                "print(output)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check format compliance\n",
                "import re\n",
                "\n",
                "def check_format(text):\n",
                "    has_reasoning = bool(re.search(r'<reasoning>.*</reasoning>', text, re.DOTALL))\n",
                "    has_answer = bool(re.search(r'<answer>.*</answer>', text, re.DOTALL))\n",
                "    return has_reasoning and has_answer\n",
                "\n",
                "print(f\"Format compliant: {check_format(output)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "total_time = (time.time() - start_time) / 60\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"SFT TRAINING COMPLETE\")\n",
                "print(\"=\"*50)\n",
                "print(f\"Total time: {total_time:.1f} minutes\")\n",
                "print(f\"Steps: {global_step}\")\n",
                "print(f\"Checkpoints saved to: checkpoints/sft/\")\n",
                "print(\"\\n‚û°Ô∏è Proceed to: 03_rl_grpo_training.ipynb\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}